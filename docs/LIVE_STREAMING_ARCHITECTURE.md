# Архитектура Live-стриминга и транскрипции

## Обзор

Система реализует real-time видеосвязь с live-транскрипцией на базе LiveKit, RTMP, FFmpeg и Gladia. Архитектура оптимизирована для минимальной задержки транскрипции и масштабируемости.

---

## Архитектура потока данных

```
┌─────────────────┐
│   Клиенты       │
│  (Браузеры)     │
└────────┬────────┘
         │ WebRTC
         ▼
┌─────────────────┐
│   LiveKit       │
│   Cloud         │
└────────┬────────┘
         │ Room Composite Egress
         │ RTMP Stream
         ▼
┌─────────────────┐      ┌──────────────────┐
│  RTMP Server    │─────▶│  RTMP Ingest     │
│  (Port 1937)    │      │  (per session)   │
└─────────────────┘      └────────┬─────────┘
                                  │ FFmpeg
                                  │ RTMP → PCM16
                                  ▼
                          ┌──────────────────┐
                          │  Gladia Bridge   │
                          │  WebSocket      │
                          └────────┬────────┘
                                   │
                                   ▼
                          ┌──────────────────┐
                          │  Gladia Live v2  │
                          │  STT API         │
                          └────────┬─────────┘
                                   │ Transcripts
                                   ▼
                          ┌──────────────────┐
                          │  WebSocket      │
                          │  Server         │
                          └────────┬────────┘
                                   │ Broadcast
                                   ▼
                          ┌──────────────────┐
                          │   Клиенты        │
                          │   (Real-time)    │
                          └──────────────────┘
```

---

## Компоненты системы

### 1. LiveKit Cloud
**Роль:** Видеосвязь и микширование аудио

- **WebRTC** для peer-to-peer соединений
- **Room Composite Egress** — один RTMP поток на комнату вместо N отдельных треков
- **Автоматическое микширование** всех участников в один аудиопоток
- **Оптимизация:** 1 Egress сессия вместо N Track Egress (экономия ресурсов)

**Преимущества:**
- Микширование на стороне LiveKit (оптимизировано)
- Идеально для speaker diarization в Gladia
- Меньше нагрузка на сеть

### 2. RTMP Server (Node-Media-Server)
**Роль:** Прием RTMP потоков от LiveKit Egress

- **Порт:** 1937 (настраивается через `RTMP_PORT`)
- **Глобальный сервер:** один экземпляр для всех сессий
- **Маршрутизация:** по `streamPath` (`/live/{sessionSlug}`)
- **Auto-ingest:** автоматическое создание обработчиков при получении потока

**Режимы работы:**
- `SERVER_MODE=rtmp` — только RTMP сервер
- `SERVER_MODE=ws` — только WebSocket сервер
- `SERVER_MODE=both` или не задан — оба сервиса

### 3. RTMP Ingest (per session)
**Роль:** Обработка RTMP потока для одной сессии

**Компоненты:**
- **FFmpeg декодер:** `rtmp://localhost:1937/live/{sessionSlug}` → PCM16 (16kHz, mono)
- **Gladia Bridge:** отправка PCM16 в Gladia Live v2
- **Active Speaker Tracker:** определение активного спикера из LiveKit

**Поток данных:**
```
RTMP Stream → FFmpeg → PCM16 (16kHz, mono) → Gladia WebSocket → Transcripts
```

**Оптимизации:**
- FFmpeg запускается только при получении реального потока (lazy start)
- Автоматический перезапуск при обрыве соединения
- Метрики аудио (байты отправленные в Gladia)

### 4. Gladia Live v2 API
**Роль:** Real-time Speech-to-Text

- **WebSocket соединение** для streaming транскрипции
- **Формат:** PCM16, 16kHz, mono
- **Режим:** Real-time (не batch)
- **Speaker Diarization:** частично доступна (лучше работает в file-based API)

**Особенности:**
- Поддержка множества языков
- Автоматическое определение языка
- Real-time транскрипты (interim + final)

### 5. WebSocket Server
**Роль:** Доставка транскриптов клиентам

**Endpoints:**
- `ws://host:port/api/realtime/transcribe` — подключение клиентов
- `POST /api/realtime/transcribe/broadcast` — прием транскриптов от RTMP сервиса

**Функции:**
- Аутентификация через JWT токены
- Broadcast транскриптов всем клиентам сессии
- Метрики подключений и сообщений
- Health check и metrics endpoints

**Оптимизации:**
- In-memory хранилище клиентов по сессиям
- Batch отправка транскриптов
- Автоматическая очистка отключенных клиентов

### 6. Transcript Batch Queue
**Роль:** Оптимизация записи транскриптов в БД

**Проблема:** При 500-1000 пользователях запись каждого транскрипта отдельно создает огромную нагрузку на БД.

**Решение:**
- In-memory очередь для pending транскриптов
- Batch запись каждые 300ms (или при достижении 100 транскриптов)
- `createMany` с `skipDuplicates` для эффективной записи
- Снижение нагрузки на БД в 10-50 раз

**Конфигурация:**
- `flushIntervalMs: 300` — интервал записи батчей
- `maxBatchSize: 100` — максимальный размер батча
- `maxQueueSize: 1000` — предупреждение при превышении

---

## Разделение сервисов

### RTMP Service (`SERVER_MODE=rtmp`)
**Задачи:**
- Прием RTMP потоков от LiveKit
- Декодирование через FFmpeg
- Отправка в Gladia
- Получение транскриптов
- Отправка транскриптов на WebSocket сервер через HTTP POST

**Порт:** 1937 (RTMP) + опционально HTTP для метрик

### WebSocket Service (`SERVER_MODE=ws`)
**Задачи:**
- Прием WebSocket подключений от клиентов
- Прием транскриптов от RTMP сервиса через HTTP POST
- Broadcast транскриптов клиентам
- Запись транскриптов в БД (batch queue)

**Порт:** 8080 (или из `PORT` env)

### Комбинированный режим (`SERVER_MODE=both` или не задан)
Оба сервиса в одном процессе (для разработки или небольших нагрузок).

---

## Технологический стек

### Backend
- **Node.js** — основной runtime
- **TypeScript** — типизация
- **Node-Media-Server** — RTMP сервер
- **FFmpeg** — декодирование аудио (RTMP → PCM16)
- **ws** — WebSocket сервер
- **Gladia Live v2** — Speech-to-Text API

### Frontend
- **Next.js 14** — React framework
- **LiveKit Client SDK** — WebRTC клиент
- **WebSocket** — получение транскриптов

### Infrastructure
- **LiveKit Cloud** — видеосвязь
- **PostgreSQL (Neon)** — база данных
- **Prisma** — ORM
- **Railway / Fly.io** — хостинг сервисов

---

## Производительность и задержки

### Текущая задержка транскрипции

**Реальная задержка (end-to-end):**
- **Текущая:** ~2-3 секунды
- **Целевая после оптимизаций:** ~800-1200ms

### Компоненты задержки и оптимизации

#### 1. LiveKit Egress → RTMP Server
**Задержка:** ~50-100ms
- Зависит от географии и качества сети
- RTMP streaming имеет небольшую буферизацию
- **Оптимизация:** Использование ближайшего региона LiveKit

#### 2. RTMP → FFmpeg декодирование
**Задержка (до оптимизации):** ~500-1000ms из-за буферизации
**Задержка (после оптимизации):** ~20-50ms

**Проблема:** FFmpeg по умолчанию буферизует 0.5-1+ секунды перед отправкой аудио.

**Оптимизации:**
- ✅ `-fflags nobuffer` — отключение буферизации
- ✅ `-flags low_delay` — минимальная задержка
- ✅ `-rtmp_live live` — режим live streaming
- ✅ `-probesize 32` — минимальный размер probe (быстрый старт)
- ✅ `-analyzeduration 0` — не анализировать поток заранее
- ✅ Reconnect флаги для стабильности

#### 3. FFmpeg → Gladia WebSocket
**Задержка (до оптимизации):** ~500-1000ms из-за больших чанков
**Задержка (после оптимизации):** ~10-30ms

**Проблема:** Большие чанки (1+ секунда аудио) добавляют задержку перед обработкой в Gladia.

**Оптимизации:**
- ✅ Разбиение на мелкие чанки: ~100-200ms аудио (3200-6400 байт при 16kHz mono PCM16)
- ✅ Отправка сразу по мере наполнения, без ожидания заполнения буфера
- ✅ Потоковая отправка вместо batch

#### 4. Gladia обработка
**Задержка:** ~200-500ms
- Real-time STT обработка
- Зависит от сложности речи и языка
- Interim транскрипты приходят быстрее
- **Оптимизация:** Не контролируется на нашей стороне

#### 5. Gladia → WebSocket Server (HTTP POST)
**Задержка:** ~100-300ms
- HTTP POST от RTMP сервиса к WebSocket сервису
- Зависит от географии сервисов
- Сериализация/десериализация JSON
- **Проблема:** Лишний сетевой хоп добавляет задержку

**Потенциальные оптимизации:**
- Запуск RTMP+WS в одном процессе для production (убирает HTTP хоп)
- Прямая запись Gladia Bridge в WebSocket клиентов (минуя HTTP API)
- Использование WebRTC для межсервисной коммуникации

#### 6. WebSocket Server → Клиент
**Задержка:** ~10-50ms
- Broadcast через WebSocket
- Зависит от качества соединения клиента
- **Оптимизация:** Транскрипты сразу бродкастятся, без накопления

### Логирование задержек

Для дебага задержек добавлено логирование timestamp на каждом этапе:

1. **Audio chunk sent to Gladia** — отправка аудио чанка
2. **Transcript received from Gladia** — получение транскрипта от Gladia
3. **Transcript posted to WS broadcast** — отправка на WebSocket сервер (с HTTP latency)
4. **Transcript delivery latency** — общая задержка доставки

Логи включают:
- `httpLatencyMs` — задержка HTTP запроса
- `totalLatencyFromGladiaMs` — общая задержка от получения от Gladia до доставки
- `timestamp` — ISO timestamp для анализа

### Реализованные оптимизации для снижения задержки

1. ✅ **Агрессивные low-latency флаги FFmpeg:**
   - `-fflags nobuffer` — отключение буферизации
   - `-flags low_delay` — минимальная задержка
   - `-probesize 32` — быстрый старт
   - `-analyzeduration 0` — без предварительного анализа
   - Reconnect флаги для стабильности

2. ✅ **Мелкие аудио-чанки:**
   - Размер чанка: ~100ms аудио (3200 байт при 16kHz mono PCM16)
   - Отправка сразу по мере наполнения
   - Потоковая отправка без ожидания заполнения буфера

3. ✅ **Lazy FFmpeg start:** FFmpeg запускается только при получении реального потока

4. ✅ **Batch queue:** запись в БД не блокирует доставку транскриптов клиентам

5. ✅ **In-memory broadcast:** транскрипты доставляются клиентам сразу, без ожидания записи в БД

6. ✅ **Логирование задержек:** timestamp на каждом этапе для дебага

### Потенциальные дальнейшие оптимизации

1. **Убрать HTTP хоп:**
   - Запуск RTMP+WS в одном процессе для production
   - Прямая запись Gladia Bridge в WebSocket клиентов

2. **География:**
   - Размещение всех сервисов в одном регионе
   - Использование edge deployment

3. **Frontend оптимизации:**
   - Рисовать interim транскрипты сразу
   - Не копить в большом стейте
   - Минимальный debounce (50-100ms)

### Пропускная способность

**На один RTMP сервер:**
- **Теоретически:** до 100+ одновременных сессий (зависит от CPU и памяти)
- **Практически:** 20-50 сессий на инстанс (с учетом FFmpeg процессов)

**На один WebSocket сервер:**
- **Теоретически:** 1000+ одновременных подключений
- **Практически:** 500-1000 подключений (зависит от нагрузки на БД)

**Масштабирование:**
- Горизонтальное масштабирование RTMP сервисов (каждый обрабатывает свои сессии)
- Горизонтальное масштабирование WebSocket сервисов (load balancing)
- Batch queue снижает нагрузку на БД в 10-50 раз

---

## Безопасность

### Аутентификация
- **JWT токены** для WebSocket подключений
- **Токены генерируются** на стороне Next.js API с использованием LiveKit API keys
- **Валидация токенов** на WebSocket сервере перед подключением

### Изоляция сессий
- Каждая сессия имеет уникальный `sessionSlug`
- Клиенты получают транскрипты только своей сессии
- RTMP потоки изолированы по `streamPath`

### Сетевая безопасность
- HTTPS для межсервисной коммуникации (RTMP → WebSocket)
- WebSocket over WSS для клиентов (в production)
- CORS headers для API endpoints

---

## Мониторинг и метрики

### Метрики RTMP сервиса
- Количество активных сессий
- Количество FFmpeg процессов
- Байты отправленные в Gladia
- Ошибки декодирования

### Метрики WebSocket сервиса
- Количество активных подключений
- Количество сообщений отправленных
- Размер batch queue
- Ошибки подключений

### Health checks
- `GET /health` — статус сервиса и размер очереди
- `GET /metrics` — детальные метрики

---

## Обработка ошибок

### RTMP Ingest
- Автоматический перезапуск FFmpeg при обрыве соединения
- Retry логика для Gladia WebSocket
- Graceful shutdown при остановке сессии

### WebSocket Server
- Автоматическая очистка отключенных клиентов
- Обработка ошибок записи в БД без падения процесса
- Fallback на in-memory broadcast при недоступности БД

### Gladia Bridge
- Автоматическое переподключение при обрыве WebSocket
- Обработка ошибок API без падения процесса
- Логирование всех ошибок для диагностики

---

## Будущие улучшения

### Потенциальные оптимизации
1. **Кэширование транскриптов** в Redis для быстрого доступа
2. **WebRTC для межсервисной коммуникации** вместо HTTP POST
3. **Edge deployment** для снижения задержки
4. **Speaker diarization** на стороне LiveKit (если будет доступно)
5. **AI-анализ транскриптов** в реальном времени (summarization, action items)

### Масштабирование
1. **Kubernetes deployment** для автоматического масштабирования
2. **Message queue** (RabbitMQ/Kafka) для межсервисной коммуникации
3. **CDN** для доставки статических ресурсов
4. **Database sharding** для больших нагрузок

---

## Заключение

Текущая архитектура обеспечивает:
- ✅ **Real-time транскрипцию** с задержкой ~500-800ms
- ✅ **Масштабируемость** через разделение сервисов
- ✅ **Надежность** через обработку ошибок и retry логику
- ✅ **Оптимизацию БД** через batch queue
- ✅ **Гибкость** через различные режимы работы сервисов

Система готова к production использованию и может масштабироваться горизонтально при росте нагрузки.

