# Реализация серверной транскрипции

## Текущий статус

Базовая структура серверного транскрайбера реализована, но требует доработки для полной функциональности.

## Что уже сделано

1. ✅ **Модуль серверного транскрайбера** (`ws/server/livekit-transcriber.ts`)
   - Подключение к LiveKit комнате как участник
   - Подписка на аудио треки участников
   - Публикация транскриптов через LiveKit data channel
   - Интеграция с Gladia bridge
   - Сохранение финальных транскриптов в БД

2. ✅ **Аудио процессор** (`ws/server/audio-processor.ts`)
   - Обработка PCM16 аудио чанков
   - Микширование нескольких аудио потоков
   - Буферизация для оптимальной отправки в Gladia

3. ✅ **Интеграция в жизненный цикл сессии**
   - Автоматический запуск при переходе сессии в статус LIVE
   - Автоматическая остановка при завершении сессии

4. ✅ **Отключение клиентской транскрипции**
   - Клиентский захват микрофона отключен
   - Транскрипты приходят только через сервер

## Что нужно доработать

### Критично: Захват аудио из LiveKit треков в Node.js

**Проблема:** LiveKit Client SDK требует браузерное окружение для работы с WebRTC. В Node.js нельзя напрямую получить аудио данные из `RemoteTrack` без полифиллов или альтернативного подхода.

**Варианты решения:**

#### Вариант 1: LiveKit Egress API (рекомендуется)

Использовать LiveKit Server SDK для создания egress, который будет отправлять аудио поток на наш сервер.

**Преимущества:**
- Официальный подход от LiveKit
- Не требует полифиллов
- Работает стабильно в production

**Недостатки:**
- Требует настройки egress
- Может быть сложнее в настройке

**Реализация:**
```typescript
import { RoomService, EgressClient, RoomCompositeEgressRequest } from 'livekit-server-sdk'

// Создаём egress для получения аудио потока
const egressClient = new EgressClient(livekitUrl, apiKey, apiSecret)
const request = new RoomCompositeEgressRequest({
  roomName: sessionSlug,
  audioOnly: true,
  // Настройка для отправки аудио на наш WebSocket сервер
})
```

#### Вариант 2: WebRTC полифиллы

Использовать библиотеку `wrtc` или `node-webrtc` для полифиллов WebRTC в Node.js.

**Преимущества:**
- Прямая работа с треками
- Полный контроль над аудио потоком

**Недостатки:**
- Требует нативных зависимостей
- Может быть нестабильно
- Сложнее в установке и поддержке

**Реализация:**
```typescript
// Установка: npm install wrtc
import 'wrtc'

// Теперь можно использовать AudioContext и MediaStream в Node.js
const audioContext = new AudioContext({ sampleRate: 16000 })
// ... обработка аудио
```

#### Вариант 3: Отдельный процесс с браузером

Использовать Puppeteer или Playwright для запуска браузера в отдельном процессе.

**Преимущества:**
- Полная совместимость с браузерными API
- Не требует изменений в коде

**Недостатки:**
- Высокое потребление ресурсов
- Сложнее в масштабировании

## План доработки

### Этап 1: Выбор подхода

1. Оценить сложность настройки LiveKit Egress API
2. Протестировать установку `wrtc` на production сервере
3. Выбрать оптимальный вариант

### Этап 2: Реализация захвата аудио

1. Реализовать выбранный подход
2. Интегрировать с существующим `AudioProcessor`
3. Протестировать захват и обработку аудио

### Этап 3: Тестирование

1. Протестировать серверную транскрипцию с несколькими участниками
2. Проверить качество транскриптов
3. Проверить производительность и нагрузку

### Этап 4: Оптимизация

1. Оптимизировать микширование аудио
2. Добавить обработку ошибок и retry логику
3. Добавить мониторинг и метрики

## Временное решение

Пока полная реализация не готова, можно использовать гибридный подход:

1. Серверный транскрайбер подключается к комнате
2. Один из участников (например, создатель сессии) временно отправляет аудио на сервер
3. Сервер транскрибирует и публикует транскрипты для всех

Это позволит протестировать остальную часть системы, пока не реализован полный захват аудио на сервере.

## Следующие шаги

1. Изучить документацию LiveKit Egress API
2. Реализовать захват аудио через выбранный подход
3. Протестировать полный цикл транскрипции
4. Оптимизировать производительность

